run:
  name: export_${.model_train_name}
  time_limit: "2:00:00"
  model_train_name: "mt5_390m"
  task_name: "xnli"
  finetuning_results_dir: ${base_results_dir}/${.model_train_name}/${.task_name}
  config_summary: tp${export.conversion.tensor_model_parallel_size}_pp${export.triton_deployment.pipeline_model_parallel_size}_${export.conversion.weight_data_type}_${export.triton_deployment.data_type}
  results_dir: ${base_results_dir}/${.model_train_name}/${.task_name}_export_${.config_summary}
  triton_model_dir: ${.results_dir}/model_repo/${.model_train_name}
  model_type: "mt5"

conversion:
  checkpoint_path: ${export.run.finetuning_results_dir}/checkpoints/megatron_mt5_glue_xnli.nemo
  # FT checkpoint will be saved in ${.triton_model_dir}/1/${.tensor_model_parallel_size}-gpu
  tensor_model_parallel_size: 8
  weight_data_type: fp16   # fp32|fp16
  processes: 16
  load_checkpoints_to_cpu: False

triton_deployment:
  max_batch_size: 1
  pipeline_model_parallel_size: 1
  int8_mode: False
  enable_custom_all_reduce: False
  data_type: fp16  # fp32|fp16|bf16

accuracy:
  ntasks_per_node: 8  # usually should be number of available gpus per node
  test_data: ${data_dir}/glue_data/xnli/xnli.test.tsv
  output_path: ${export.run.results_dir}/eval_output.json
  batch_size: 64
  max_output_len: 512
  runtime:
    beam_width: 1
    sampling_top_k: 1
    sampling_top_p: 0

benchmark:
  tensor_model_parallel_size: 8
  pipeline_model_parallel_size: 1
  input_len: 60
  output_len: 20
  batch_sizes: [1, 2, 4, 8, 16, 32, 64, 128, 256]
  triton_wait_time: 300
