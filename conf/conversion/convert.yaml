run:
  job_name: convert_${conversion.run.model_train_name}
  nodes: 1
  time_limit: "4:00:00"
  ntasks_per_node: ${conversion.model.tensor_model_parallel_size}
  gpus_per_task: 1
  convert_name: convert_nemo
  model_train_name: 5b
  results_dir: ${base_results_dir}/${.model_train_name}/conversion
  output_path: ${base_results_dir}/${.model_train_name}/conversion
  nemo_file_name: megatron_gpt.nemo # name of nemo checkpoint; must be .nemo file

model:
  checkpoint_folder: ${base_results_dir}/${conversion.run.model_train_name}/checkpoints
  checkpoint_name: latest # latest OR name pattern of a checkpoint (e.g. megatron_gpt-*last.ckpt)
  tensor_model_parallel_size: 2 # 1 for 126m, 2 for 5b, and 8 for 20b
  vocab_file: ${data_dir}/bpe/vocab.json
  merge_file: ${data_dir}/bpe/merges.txt
