variables: &VARS
  BIGNLP_REGISTRY: "gitlab-master.nvidia.com:5005/dl/joc/bignlp-scripts"
  BIGNLP_BASE_IMAGE: "nvcr.io/ea-bignlp/bignlp-training:22.04-py3"
  BIGNLP_CI_PATH: "/lustre/fsw/joc/big_nlp/bignlp_ci"

stages:
  - build
  - test
  - upload_results

################
# JOB Templates
################

test:unit_tests:
  tags:
    - V100
  stage: test
  script:
    - pip install -r requirements.txt
    - pip install pytest
    - pip install requests-mock
    - export PATH="/home/gitlab-runner/.local/bin:$PATH"
    - pytest tests/unit_tests
  rules:
    - when: never

before_script:
  - export DOCKERFILE=./Dockerfile
  - if [[ -z ${BASE_IMAGE} ]]; then
      export BASE_IMAGE=$(grep -oP "ARG FROM_IMAGE_NAME=\K\S+" ${DOCKERFILE});
    else
      export FROM_IMAGE_NAME=$BASE_IMAGE;
    fi
  - export IMAGE_NAME=${BASE_IMAGE##*/}
  - export IMAGE_NAME=${IMAGE_NAME%:*}
  - export BUILD_IMAGE_NAME=${BIGNLP_REGISTRY}/${IMAGE_NAME}:pipe.${CI_PIPELINE_ID}
  - export BUILD_IMAGE_NAME_SRUN="${BUILD_IMAGE_NAME/:5005\//#}"
  - export PIPELINE_DIR="${BIGNLP_CI_PATH}/${CI_PIPELINE_ID}"
  - export BASE_RESULTS_DIR="${PIPELINE_DIR}/results"

.build: &build_template
  stage: build
  script:
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN "${CI_REGISTRY}"
    - export DOCKER_REGISTRY="${CI_REGISTRY/:5005/}"
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN "${DOCKER_REGISTRY}"
    # Define bignlp build image
    - set -x
    - ls
    - env
    - export FROM_IMAGE_ARG="--build-arg FROM_IMAGE_NAME=${BASE_IMAGE}"
    - docker build -t ${BUILD_IMAGE_NAME} ${FROM_IMAGE_ARG} .
    - docker push ${BUILD_IMAGE_NAME}
  allow_failure: false
  tags:
    - vm-builder

.LUNA: &LUNA
  variables: &LUNA_VARS
    SLURM_PARTITION: "luna"
    SLURM_NIGHTLY_PARTITION: "luna"
    SLURM_ACCOUNT: "joc"
    CLUSTER:       "selene"
    PYXIS_LITE:    "1"
    ENROOT_MOUNT_HOME: "n"
    GIT_CLONE_PATH: $CI_BUILDS_DIR/$SLURM_ACCOUNT/big_nlp/bignlp_ci/$CI_PIPELINE_ID/$CI_JOB_ID/$CI_PROJECT_NAME # THIS DOES NOT HAVE QUOTES FOR A REASON
    EXCLUDE_NODES: ""
    GPU_ARCH:      "A100"
  tags: &LUNA_TAGS
    - selene_ssh

build-BigNLP:
  <<: *build_template


.bignlp-LUNA-test-LAUNCHER: &bignlp-LUNA-test-LAUNCHER
  tags: *LUNA_TAGS
  stage: test
  script: &bignlp-LUNA-test-LAUNCHER-SCRIPT
    - chmod -R 774 ${GIT_CLONE_PATH}/*
    - source /lustre/fsw/joc/big_nlp/nemo_gpt3/my_venv/bin/activate
    - set -x
    - export RESULTS_DIR=${BASE_RESULTS_DIR}/${RUN_NAME}
    - env
    - bash tests/ci_tests/selene/scripts/${RUN_NAME}.sh
    # Wait for job to launch
    - sleep 10s # Without this, "sacct" in jobstate.sh does not always find the SLURM job.
    - export SLURM_JOBID=$(grep 'Submitted batch job' "${RESULTS_DIR}/launcher.log" | awk '{ print $4 }')
    - echo $SLURM_JOBID
    - export SLURM_OUTPUT=${RESULTS_DIR}/slurm_${SLURM_JOBID}.log
    #export SLURM_OUTPUT=$(scontrol show job "${SLURM_JOBID}" | grep 'StdOut' | awk -F '=' '{ print $2 }')
    - cd tests/ci_tests/utils
    - chmod 777 ./* -R
    - bash jobwait.sh "${SLURM_JOBID}" & PID=$!
    - touch "${SLURM_OUTPUT}"
    - \[ ! -z ${SLURM_JOBID} \] && echo -e " --------------------------------------------------\n"
                "----------WAITING FOR SLURM JOB TO BEGIN-----------\n"
                "---------------------------------------------------\n"
                "$(scontrol show job=${SLURM_JOBID})\n"
                "---------------------------------------------------\n"
    # Gitlab logs collapsible section markers
    - echo -e "\e[0Ksection_end:`date +%s`:slurm_setup\r\e[0K"
    # Follow output of the job
    - tail --pid="${PID}" -f "${SLURM_OUTPUT}" # Stream job output until it finishes.
    - echo "Finished job with name ${RUN_NAME}"
    - cd ${GIT_CLONE_PATH}

    # Run Pytest
    - pip3 install pytest
    - pytest tests/ci_tests/selene/pytest/test_${RUN_NAME}.py
    - echo "Finished pytest job"

    # Run metrics collection
    - python3 tests/ci_tests/utils/covert_ci_metric_to_json.py tests/ci_tests/selene/pytest/test_${RUN_NAME}.py
  allow_failure: false

train.gpt3.126m_tp1_pp1_1node_100steps:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: train_gpt3_126m_tp1_pp1_1node_100steps
  rules:
    - when: never
  needs:
    - build-BigNLP

train.gpt3.126m_tp2_pp1_1node_100steps:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: train_gpt3_126m_tp2_pp1_1node_100steps
  rules:
    - when: never
  needs:
    - build-BigNLP

train.gpt3.126m_tp1_pp2_2node_100steps:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: train_gpt3_126m_tp1_pp2_2node_100steps
  rules:
    - when: never
  needs:
    - build-BigNLP

train.gpt3.126m_tp2_pp2_2node_100steps:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: train_gpt3_126m_tp2_pp2_2node_100steps
  rules:
    - when: never
  needs:
    - build-BigNLP

train.t5.220m_tp1_pp1_1node_100steps:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: train_t5_220m_tp1_pp1_1node_100steps
  rules:
    - when: always
  needs:
    - build-BigNLP


eval.gpt3.126m_tp1_pp1_lambada:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: eval_gpt3_126m_tp1_pp1_lambada
  rules:
    - when: never
  needs:
    - train.gpt3.126m_tp1_pp1_1node_100steps


eval.gpt3.126m_tp2_pp1_lambada:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: eval_gpt3_126m_tp2_pp1_lambada
  rules:
    - when: never
  needs:
    - train.gpt3.126m_tp2_pp1_1node_100steps


eval.gpt3.126m_tp1_pp2_lambada:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: eval_gpt3_126m_tp1_pp2_lambada
  rules:
    - when: never
  needs:
    - train.gpt3.126m_tp1_pp2_2node_100steps


eval.gpt3.126m_tp2_pp2_lambada:
  <<: *bignlp-LUNA-test-LAUNCHER
  variables:
    <<: [*VARS, *LUNA_VARS]
    RUN_NAME: eval_gpt3_126m_tp2_pp2_lambada
  rules:
    - when: never
  needs:
    - train.gpt3.126m_tp2_pp2_2node_100steps
